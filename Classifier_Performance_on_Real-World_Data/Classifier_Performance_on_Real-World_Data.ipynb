{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ ME\n",
    "\n",
    "Group Members:Ryan McDonald, Justin Drouin\n",
    "  \n",
    "This project loads the UCI bank marketing data set and trains a series of classifiers to make predictions on both the original dataset and a balanced version of the training data set. Each classifier is then scored against the full data set for testing.\n",
    "\n",
    "**Experiments**\n",
    "\n",
    "\n",
    "**1) Download bank-additional.zip and extract its contents. Since the dataset is large and some of the algorithms we will use can be time-consuming, we will train with bank-additional.csv, which is a subset of the original dataset.\n",
    "Once our models are trained, we will test against the full dataset, which is in bank-additional-full.csv. The archive also contains a text file, bank-additional-names.txt, which describes the dataset and what each column represents.**\n",
    "\n",
    "\n",
    "\n",
    "**2) Use read_csv() to load and examine the training and test sets. Unlike most CSV files, the separator is actually ';' rather than ','.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "bankdata = pd.read_csv('bank-additional.csv',sep = ';')\n",
    "bankdatafull = pd.read_csv('bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) The training and test DataFrames will need some significant preprocessing before they can be used:**\n",
    "\n",
    "**a) Several of the features are categorical variables and will need to be turned into numbers before they can be used by ML algorithms. The simplest way to accomplish this is to use dummy coding using the Pandas get_dummies() method.**\n",
    "\n",
    "**Note: some algorithms (e.g. logistic regression) have problems with collinear features. If you use one-hot encoding, one dummy variable will be a linear combination of the other dummy variables, so be sure to pass drop_first=True.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata_dummies = pd.get_dummies(bankdata, drop_first=True)\n",
    "bankdatafull_dummies = pd.get_dummies(bankdatafull, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Two features should be removed from the dataset:**\n",
    "\n",
    "**Per bank-additional-names.txt, the duration “should be discarded if the intention is to have a realistic predictive model.”**\n",
    "\n",
    "**The feature y (or y_yes after dummy coding) is the target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata_dummies_duration_dropped = bankdata_dummies.drop(labels='duration', axis=1)\n",
    "bankdatafull_dummies_duration_dropped = bankdatafull_dummies.drop(labels='duration', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Some algorithms (e.g. KNN and SVM) require non-categorical features to be standardized.**\n",
    "\n",
    "According to bank-additional-names, the list of columns that are non-categorical features:\n",
    "age, campaign, pdays, previous, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed\n",
    "Standardization used: standardized_value = (value - mean of column) / standard deviation of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_features = bankdata_dummies_duration_dropped.loc[:, bankdata_dummies_duration_dropped.columns != 'y_yes']\n",
    "training_set_target = bankdata_dummies_duration_dropped['y_yes']\n",
    "\n",
    "test_set_features = bankdatafull_dummies_duration_dropped.loc[:, bankdatafull_dummies_duration_dropped.columns != 'y_yes']\n",
    "test_set_target = bankdatafull_dummies_duration_dropped['y_yes']\n",
    "\n",
    "#List of cols to standardize\n",
    "to_standardize = 'age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
    "\n",
    "#Standardize all features in test and training datasets\n",
    "for col in to_standardize:\n",
    "    bankdata_dummies_duration_dropped[col] = (bankdata_dummies_duration_dropped[col]-bankdata_dummies_duration_dropped[col].mean())/bankdata_dummies_duration_dropped[col].std()\n",
    "    bankdatafull_dummies_duration_dropped[col] = (bankdatafull_dummies_duration_dropped[col]-bankdatafull_dummies_duration_dropped[col].mean())/bankdatafull_dummies_duration_dropped[col].std()\n",
    "\n",
    "#Separate dataframes into training/testing features & targets for ease of use later\n",
    "training_set_features_standardized = bankdata_dummies_duration_dropped.loc[:, bankdata_dummies_duration_dropped.columns != 'y_yes']\n",
    "training_set_target_standardized = bankdata_dummies_duration_dropped['y_yes']\n",
    "\n",
    "test_set_features_standardized = bankdatafull_dummies_duration_dropped.loc[:, bankdatafull_dummies_duration_dropped.columns != 'y_yes']\n",
    "test_set_target_standardized = bankdatafull_dummies_duration_dropped['y_yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Fit Naive Bayes, KNN, and SVM classifiers to the training set, then score each classifier on the test set. Which classifier has the highest accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545450131106147"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Guassian Naive Bayes\n",
    "gnb_training = GaussianNB().fit(training_set_features, training_set_target)\n",
    "gnb_training.score(test_set_features, test_set_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929057006895212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-Nearest Neighbors\n",
    "knn_training = sklearn.neighbors.KNeighborsClassifier().fit(training_set_features_standardized, training_set_target_standardized)\n",
    "knn_training.score(test_set_features_standardized, test_set_target_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899436729144411"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "svm_training = SVC().fit(training_set_features_standardized, training_set_target_standardized)\n",
    "svm_training.score(test_set_features_standardized, test_set_target_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) These numbers look pretty good, but let’s take another look at the data. How many values in the training set have y_yes = 0, and how many have y_yes = 1? What would be the accuracy if we simply assumed that no customer ever subscribed to the product?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of y_yes in training set = 0: 3668\n",
      "Number of y_yes in training set = 1: 451\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of y_yes in training set = 0:\", training_set_target.isin([0]).sum())\n",
    "print(\"Number of y_yes in training set = 1:\", training_set_target.isin([1]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "89.05% of customers in the training set have not subscribed to the product. If we assume that that no customer ever subscribed we would have roughly 89% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Use np.zeros_like() to create a target vector representing the output of the “dumb” classifier of experiment (5), then create a confusion matrix and find its AUC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3668,  451],\n",
       "       [   0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroes = np.zeros_like(training_set_target)\n",
    "confusion_matrix(zeroes, training_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 3668\n",
    "\n",
    "(Incorrect) False Positives: 451\n",
    "\n",
    "(Incorrect) False Negative: 0\n",
    "\n",
    "(Correct) True Negative: 0\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 3668 / 4119 = 89.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(training_set_target, zeroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)Create a confusion matrix and find the AUC for each of the classifiers of experiment (4). Is the best classifier the one with the highest accuracy?**\n",
    "\n",
    "**Gaussian Naive Bayes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33020,  2463],\n",
       "       [ 3528,  2177]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(gnb_training.predict(test_set_features), test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 33020\n",
    "\n",
    "(Incorrect) False Positives: 2463\n",
    "\n",
    "(Incorrect) False Negative: 3528\n",
    "\n",
    "(Correct) True Negative: 2177\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 35197 / 41188 = **85.45%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes AUC Score:  0.6863252222867992\n"
     ]
    }
   ],
   "source": [
    "print(\"Gaussian Naive Bayes AUC Score: \", roc_auc_score(test_set_target, gnb_training.predict(test_set_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35577,  3440],\n",
       "       [  971,  1200]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(knn_training.predict(test_set_features_standardized), test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 35577\n",
    "\n",
    "(Incorrect) False Positives: 3440\n",
    "\n",
    "(Incorrect) False Negative: 971\n",
    "\n",
    "(Correct) True Negative: 1200\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 36777 / 41188 = **89.29%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors AUC Score:  0.616026444203749\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Nearest Neighbors AUC Score: \", roc_auc_score(test_set_target, knn_training.predict(test_set_features_standardized)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36217,  3811],\n",
       "       [  331,   829]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svm_training.predict(test_set_features_standardized), test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 36217\n",
    "\n",
    "(Incorrect) False Positives: 3811\n",
    "\n",
    "(Incorrect) False Negative: 331\n",
    "\n",
    "(Correct) True Negative: 829\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 37046 / 41188 = **89.94%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine AUC Score:  0.5848036049899423\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine AUC Score: \",roc_auc_score(test_set_target, svm_training.predict(test_set_features_standardized)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Guassian Naive Bayes classifier had the lowest accuracy out of all three of the classifiers, however it had the highest AUC score. \n",
    "\n",
    "**8)One of the easiest ways to deal with an unbalanced dataset is random oversampling. This can be done with an imblearn.over_sampling.RandomOverSampler object. Use fit_resample() to generate a balanced training set. To make sure that your results are reproducible, pass random_state=(2021-4-22).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=2021-4-22)\n",
    "\n",
    "training_set_features_res, training_set_target_res = ros.fit_resample(training_set_features, training_set_target)\n",
    "training_set_features_standardized_res, training_set_target_standardized_res = ros.fit_resample(training_set_features_standardized, training_set_target_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)Repeat experiments (4) and (7) on the balanced training set of experiment (8). Which classifier performs the best, and how much better is its performance?**\n",
    "\n",
    "**9-4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB resampled score:  0.8446392153054287\n",
      "KNN resampled score:  0.7636690298145091\n",
      "SVM resampled score:  0.8547635233563173\n"
     ]
    }
   ],
   "source": [
    "#Guassian Naive Bayes\n",
    "gnb_training_res = GaussianNB().fit(training_set_features_res, training_set_target_res)\n",
    "print(\"GNB resampled score: \",gnb_training_res.score(test_set_features, test_set_target))\n",
    "\n",
    "#K-Nearest Neighbors\n",
    "knn_training_res = sklearn.neighbors.KNeighborsClassifier().fit(training_set_features_standardized_res, training_set_target_standardized_res)\n",
    "print(\"KNN resampled score: \",knn_training_res.score(test_set_features_standardized, test_set_target_standardized))\n",
    "\n",
    "#Support Vector Machine\n",
    "svm_training_res = SVC().fit(training_set_features_standardized_res, training_set_target_standardized_res)\n",
    "print(\"SVM resampled score: \",svm_training_res.score(test_set_features_standardized, test_set_target_standardized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9-7)**\n",
    "\n",
    "**Gaussian Naive Bayes Resampled:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32481,  2332],\n",
       "       [ 4067,  2308]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(gnb_training_res.predict(test_set_features), test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 32481\n",
    "\n",
    "(Incorrect) False Positives: 2332\n",
    "\n",
    "(Incorrect) False Negative: 4067\n",
    "\n",
    "(Correct) True Negative: 2308\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 34789 / 41188 = **84.46%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Resampled AUC Score:  0.6930677370901941\n"
     ]
    }
   ],
   "source": [
    "print(\"Gaussian Naive Bayes Resampled AUC Score: \", roc_auc_score(test_set_target, gnb_training_res.predict(test_set_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors Resampled:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28687,  1873],\n",
       "       [ 7861,  2767]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(knn_training_res.predict(test_set_features_standardized), test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 28687\n",
    "\n",
    "(Incorrect) False Positives: 1873\n",
    "\n",
    "(Incorrect) False Negative: 7861\n",
    "\n",
    "(Correct) True Negative: 2767\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 31454 / 41188 = **76.37%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Resampled AUC Score:  0.6906245990157488\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Nearest Neighbors Resampled AUC Score: \", roc_auc_score(test_set_target, knn_training_res.predict(test_set_features_standardized)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine Resampled:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32453,  1887],\n",
       "       [ 4095,  2753]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svm_training_res.predict(test_set_features_standardized), test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correct) True Positives: 32453\n",
    "\n",
    "(Incorrect) False Positives: 1887\n",
    "\n",
    "(Incorrect) False Negative: 4095\n",
    "\n",
    "(Correct) True Negative: 2753\n",
    "\n",
    "\n",
    "Accuracy = (TP + TN) / (P + N) = 37046 / 41188 = **85.48%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Resampled AUC Score:  0.7406372654006257\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine Resampled AUC Score: \",roc_auc_score(test_set_target, svm_training_res.predict(test_set_features_standardized)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the imbalanced learn random oversampling on our classifier models, the model with the highest accuracy also had the highest AUC score. Unlike on the previous experiments, the support vector machine model was most accurate as well as had the highest AUC when using a balanced training set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
